{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "class FrameConverter:\n",
    "    def __init__(self, X_transforms=[], y_transforms=[], repeat_count=1, n_parallel=1):\n",
    "        self.filename_dir = '/home/data/full/frame/'\n",
    "        self.filename_base = '/home/data/full/frame/{}{}.tfrecord'\n",
    "        self.X_transforms = X_transforms\n",
    "        self.y_transforms = y_transforms\n",
    "        self.repeat_count = repeat_count\n",
    "        self.n_parallel = n_parallel\n",
    "        \n",
    "        self.keys_to_features = {\n",
    "            'rgb': tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "            'audio': tf.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "        }\n",
    "        self.key_to_label = {\n",
    "            'labels': tf.VarLenFeature(tf.int64)\n",
    "        }\n",
    "        \n",
    "    def get_data(self, filename):\n",
    "        y, X = tf.parse_single_sequence_example(filename,\n",
    "                                                self.key_to_label,\n",
    "                                                self.keys_to_features)\n",
    "        # X is still bytes; convert to float\n",
    "        X['audio'] = tf.cast(tf.decode_raw(X['audio'], tf.uint8), tf.float32)\n",
    "        X['rgb'] = tf.cast(tf.decode_raw(X['rgb'], tf.uint8), tf.float32)\n",
    "\n",
    "        # now apply custom transformations\n",
    "        for transform in self.X_transforms:\n",
    "            X = transform(X)\n",
    "\n",
    "        y = tf.sparse_to_dense(y['labels'].values, [3862], 1)\n",
    "        for transform in self.y_transforms:\n",
    "            y = transform(y)\n",
    "        return X, y\n",
    "    \n",
    "    def make_provider(self, subset, record_indices=None):\n",
    "        if record_indices:\n",
    "            filenames = [self.filename_dir + f'{subset}{index}.tfrecord'\n",
    "                         for index in record_indices]\n",
    "        else:\n",
    "            filenames = os.listdir(self.filename_dir)\n",
    "        \n",
    "        dataset = tf.data.TFRecordDataset(filenames)\n",
    "        dataset = dataset.map(self.get_data,\n",
    "                              num_parallel_calls=self.n_parallel)\n",
    "        dataset = dataset.repeat(self.repeat_count)\n",
    "        dataset = dataset.shuffle(buffer_size=256)\n",
    "            \n",
    "        dataset = dataset.batch(1)\n",
    "        dataset = dataset.prefetch(1)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        return iterator\n",
    "    \n",
    "    def make_generator(self, subset, record_indices):\n",
    "        self.provider = self.make_provider(subset, record_indices)\n",
    "        sess = tf.Session()\n",
    "        next_sample = self.provider.get_next()\n",
    "        while True:\n",
    "            try:\n",
    "                yield sess.run(next_sample)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"Iterations exhausted\")\n",
    "                break\n",
    "    \n",
    "frame_converter = FrameConverter(n_parallel=3)\n",
    "train_generator = frame_converter.make_generator('train', [2500, 2501, 2502])\n",
    "valid_generator = frame_converter.make_generator('validate', [2000, 2001, 2002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Flatten, Add\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "n_classes = 3862\n",
    "rgb_in = Input((None, 1024), name='rgb')\n",
    "audio_in = Input((None, 128), name='audio')\n",
    "rgb_mid = GRU(512, activation='relu')(rgb_in)\n",
    "audio_mid = GRU(512, activation='relu')(audio_in)\n",
    "combined_mid = Add()([rgb_mid, audio_mid])\n",
    "out = Dense(32, activation='relu')(combined_mid)\n",
    "out = Dense(n_classes, activation='softmax')(out)\n",
    "model = Model([rgb_in, audio_in], out)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30/30 [==============================] - 13s 441ms/step - loss: 0.0149 - acc: 0.9989 - val_loss: 0.0160 - val_acc: 0.9990\n",
      "Epoch 2/2\n",
      "30/30 [==============================] - 12s 398ms/step - loss: 0.0167 - acc: 0.9989 - val_loss: 0.0113 - val_acc: 0.9991\n",
      "26.148629426956177\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "model.fit_generator(train_generator, steps_per_epoch=30, epochs=2,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=20)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30/30 [==============================] - 13s 431ms/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0083 - val_acc: 0.9990\n",
      "Epoch 2/2\n",
      "30/30 [==============================] - 13s 432ms/step - loss: 0.0072 - acc: 0.9992 - val_loss: 0.0063 - val_acc: 0.9993\n",
      "26.875075101852417\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "model.fit_generator(train_generator, steps_per_epoch=30, epochs=2,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=20)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.0170 - val_loss: 0.0050\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 7.2338e-04 - val_loss: 0.0043\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9727e-04 - val_loss: 0.0040\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.0383e-04 - val_loss: 0.0037\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 7.3688e-05 - val_loss: 0.0037\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 6.0131e-05 - val_loss: 0.0038\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.6094e-05 - val_loss: 0.0038\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.6601e-05 - val_loss: 0.0042\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.3661e-05 - val_loss: 0.0038\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.1280e-05 - val_loss: 0.0041\n",
      "30.176326990127563\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from glob import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def parser(record, training=True):\n",
    "    \"\"\"\n",
    "    In training mode labels will be returned, otherwise they won't be\n",
    "    \"\"\"\n",
    "    keys_to_features = {\n",
    "        \"mean_rgb\": tf.FixedLenFeature([1024], tf.float32),\n",
    "        \"mean_audio\": tf.FixedLenFeature([128], tf.float32)\n",
    "    }\n",
    "    \n",
    "    if training:\n",
    "        keys_to_features[\"labels\"] =  tf.VarLenFeature(tf.int64)\n",
    "    \n",
    "    parsed = tf.parse_single_example(record, keys_to_features)\n",
    "    x = tf.concat([parsed[\"mean_rgb\"], parsed[\"mean_audio\"]], axis=0)\n",
    "    if training:\n",
    "        y = tf.sparse_to_dense(parsed[\"labels\"].values, [3862], 1)\n",
    "        return x, y\n",
    "    else:\n",
    "        x = tf.concat([parsed[\"mean_rgb\"], parsed[\"mean_audio\"]], axis=0)\n",
    "        return x\n",
    "    \n",
    "def make_datasetprovider(tf_records, repeats=1000, num_parallel_calls=12, \n",
    "                         batch_size=32): \n",
    "    \"\"\"\n",
    "    tf_records: list of strings - tf records you are going to use.\n",
    "    repeats: how many times you want to iterate over the data.\n",
    "    \"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(tf_records)\n",
    "    dataset = dataset.map(map_func=parser, num_parallel_calls=num_parallel_calls)\n",
    "    dataset = dataset.repeat(repeats)\n",
    "\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(batch_size)\n",
    "\n",
    "    d_iter = dataset.make_one_shot_iterator()\n",
    "    return d_iter\n",
    "\n",
    "def data_generator(tf_records, batch_size=32, repeats=1000, num_parallel_calls=1, ):\n",
    "    tf_provider = make_datasetprovider(tf_records, repeats=repeats, num_parallel_calls=num_parallel_calls,\n",
    "                                       batch_size=batch_size)\n",
    "    sess = tf.Session()\n",
    "    next_el = tf_provider.get_next()\n",
    "    while True:\n",
    "        try:\n",
    "          yield sess.run(next_el)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"Iterations exhausted\")\n",
    "            break\n",
    "            \n",
    "def fetch_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2048, activation=\"relu\", input_shape=(1024 + 128,)))\n",
    "    model.add(Dense(3862, activation=\"sigmoid\"))\n",
    "    model.compile(\"adam\", loss=\"binary_crossentropy\")\n",
    "    return model\n",
    "\n",
    "train_data = glob(\"/home/data/full//video/train2000.tfrecord\")\n",
    "eval_data = glob(\"/home/data/full/video/train2001.tfrecord\")\n",
    "\n",
    "my_train_iter = data_generator(train_data)\n",
    "my_eval_iter = data_generator(eval_data)\n",
    "model = fetch_model()\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit_generator(my_train_iter,\n",
    "                    steps_per_epoch=300,\n",
    "                    epochs=10, \n",
    "                    validation_data=my_eval_iter, \n",
    "                    validation_steps=20)\n",
    "print(time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
